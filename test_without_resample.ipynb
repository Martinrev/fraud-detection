{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dataframe.pkl', 'rb') as file:\n",
    "    df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On définit la partie Train et Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des dates limites pour les ensembles d'apprentissage et de test\n",
    "train_inf = '2017-02-01'\n",
    "train_sup = '2017-08-31'\n",
    "test_inf = '2017-09-01'\n",
    "test_sup = '2017-11-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.loc[(df['DateTransaction'] >= train_inf) & (df['DateTransaction'] <= train_sup)]\n",
    "X_train = train.drop(columns=['FlagImpaye','CodeDecision','DateTransaction'])\n",
    "y_train = train['FlagImpaye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.loc[(df['DateTransaction'] >= test_inf) & (df['DateTransaction'] <= test_sup)]\n",
    "X_test = test.drop(columns=['FlagImpaye','CodeDecision','DateTransaction'])\n",
    "y_test = test['FlagImpaye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3888468\n",
      "737068\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de chaque méthode d'échantillonage par modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "#!pip install 'imblearn'\n",
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les stratégies d'échantillonnage\n",
    "sampling_strategies = [0.05, 0.1]  # Ajoutez les valeurs que vous souhaitez tester\n",
    "#on garde deux oversampling et deux undersampling\n",
    "samplers = [RandomOverSampler, SMOTE, RandomUnderSampler, NearMiss]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait tourner DecisionTreeClassifier, RandomForestClassifier, GradientBoostingClassifier,KNeighborsClassifier, SVC, adaboost, xgboost et LogisticRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26524\\1770478157.py:23: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df_no_sampling = pd.concat([results_df_no_sampling, pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeClassifier, Sampler: RandomOverSampler, Strategy: 0.05, F1 Score: 0.02942850174782538\n",
      "Model: DecisionTreeClassifier, Sampler: RandomOverSampler, Strategy: 0.1, F1 Score: 0.030453588024375734\n",
      "Model: DecisionTreeClassifier, Sampler: SMOTE, Strategy: 0.05, F1 Score: 0.029341692789968652\n",
      "Model: DecisionTreeClassifier, Sampler: SMOTE, Strategy: 0.1, F1 Score: 0.03085717997856238\n",
      "Model: DecisionTreeClassifier, Sampler: RandomUnderSampler, Strategy: 0.05, F1 Score: 0.030474097017535094\n",
      "Model: DecisionTreeClassifier, Sampler: RandomUnderSampler, Strategy: 0.1, F1 Score: 0.031470992391996515\n",
      "Model: DecisionTreeClassifier, Sampler: NearMiss, Strategy: 0.05, F1 Score: 0.030382980153595376\n",
      "Model: DecisionTreeClassifier, Sampler: NearMiss, Strategy: 0.1, F1 Score: 0.03037588122543127\n",
      "                    Model             Sampler  Sampling Strategy  F1 Score\n",
      "0  DecisionTreeClassifier   RandomOverSampler               0.05  0.029429\n",
      "1  DecisionTreeClassifier   RandomOverSampler               0.10  0.030454\n",
      "2  DecisionTreeClassifier               SMOTE               0.05  0.029342\n",
      "3  DecisionTreeClassifier               SMOTE               0.10  0.030857\n",
      "4  DecisionTreeClassifier  RandomUnderSampler               0.05  0.030474\n",
      "5  DecisionTreeClassifier  RandomUnderSampler               0.10  0.031471\n",
      "6  DecisionTreeClassifier            NearMiss               0.05  0.030383\n",
      "7  DecisionTreeClassifier            NearMiss               0.10  0.030376\n"
     ]
    }
   ],
   "source": [
    "# Définir les modèles à tester\n",
    "models = [DecisionTreeClassifier()]\n",
    "\n",
    "# Initialiser un DataFrame pour stocker les résultats\n",
    "results_df_no_sampling = pd.DataFrame(columns=['Model', 'Sampler', 'Sampling Strategy', 'F1 Score'])\n",
    "\n",
    "# Parcourir chaque modèle\n",
    "for model in models:\n",
    "    # Boucler sur chaque échantillonneur (sampler)\n",
    "    for sampler in samplers:\n",
    "        # Parcourir chaque valeur de sampling_strategy\n",
    "        for strategy in sampling_strategies:\n",
    "            # Entraîner le modèle sur les données d'entraînement d'origine\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Faire des prédictions sur l'ensemble de test\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Évaluer les performances du modèle\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            # Ajouter les résultats au DataFrame\n",
    "            results_df_no_sampling = pd.concat([results_df_no_sampling, pd.DataFrame({\n",
    "                'Model': [model.__class__.__name__],\n",
    "                'Sampler': [sampler.__name__],\n",
    "                'Sampling Strategy': [strategy],\n",
    "                'F1 Score': [f1]\n",
    "            })], ignore_index=True)\n",
    "\n",
    "            # Afficher le message de progression\n",
    "            tqdm.write(f\"Model: {model.__class__.__name__}, Sampler: {sampler.__name__}, Strategy: {strategy}, F1 Score: {f1}\")\n",
    "\n",
    "# Afficher le tableau récapitulatif\n",
    "print(results_df_no_sampling)\n",
    "results_df_no_sampling.to_pickle('dataframe_recap_no_sampling.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26524\\2629868936.py:23: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df_no_sampling_2 = pd.concat([results_df_no_sampling_2, pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier, Sampler: RandomOverSampler, Strategy: 0.05, F1 Score: 0.038950276243093926\n"
     ]
    }
   ],
   "source": [
    "# Définir les modèles à tester\n",
    "models = [RandomForestClassifier()]\n",
    "\n",
    "# Initialiser un DataFrame pour stocker les résultats\n",
    "results_df_no_sampling_2 = pd.DataFrame(columns=['Model', 'Sampler', 'Sampling Strategy', 'F1 Score'])\n",
    "\n",
    "# Parcourir chaque modèle\n",
    "for model in models:\n",
    "    # Boucler sur chaque échantillonneur (sampler)\n",
    "    for sampler in samplers:\n",
    "        # Parcourir chaque valeur de sampling_strategy\n",
    "        for strategy in sampling_strategies:\n",
    "            # Entraîner le modèle sur les données d'entraînement d'origine\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Faire des prédictions sur l'ensemble de test\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Évaluer les performances du modèle\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            # Ajouter les résultats au DataFrame\n",
    "            results_df_no_sampling_2 = pd.concat([results_df_no_sampling_2, pd.DataFrame({\n",
    "                'Model': [model.__class__.__name__],\n",
    "                'Sampler': [sampler.__name__],\n",
    "                'Sampling Strategy': [strategy],\n",
    "                'F1 Score': [f1]\n",
    "            })], ignore_index=True)\n",
    "\n",
    "            # Afficher le message de progression\n",
    "            tqdm.write(f\"Model: {model.__class__.__name__}, Sampler: {sampler.__name__}, Strategy: {strategy}, F1 Score: {f1}\")\n",
    "\n",
    "# Afficher le tableau récapitulatif\n",
    "print(results_df_no_sampling_2)\n",
    "results_df_no_sampling_2.to_pickle('dataframe_recap_no_sampling_2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les modèles à tester\n",
    "models = [SVC()]\n",
    "\n",
    "# Initialiser un DataFrame pour stocker les résultats\n",
    "results_df_no_sampling_3 = pd.DataFrame(columns=['Model', 'Sampler', 'Sampling Strategy', 'F1 Score'])\n",
    "\n",
    "# Parcourir chaque modèle\n",
    "for model in models:\n",
    "    # Boucler sur chaque échantillonneur (sampler)\n",
    "    for sampler in samplers:\n",
    "        # Parcourir chaque valeur de sampling_strategy\n",
    "        for strategy in sampling_strategies:\n",
    "            # Entraîner le modèle sur les données d'entraînement d'origine\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Faire des prédictions sur l'ensemble de test\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Évaluer les performances du modèle\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            # Ajouter les résultats au DataFrame\n",
    "            results_df_no_sampling_3 = pd.concat([results_df_no_sampling_3, pd.DataFrame({\n",
    "                'Model': [model.__class__.__name__],\n",
    "                'Sampler': [sampler.__name__],\n",
    "                'Sampling Strategy': [strategy],\n",
    "                'F1 Score': [f1]\n",
    "            })], ignore_index=True)\n",
    "\n",
    "            # Afficher le message de progression\n",
    "            tqdm.write(f\"Model: {model.__class__.__name__}, Sampler: {sampler.__name__}, Strategy: {strategy}, F1 Score: {f1}\")\n",
    "\n",
    "# Afficher le tableau récapitulatif\n",
    "print(results_df_no_sampling_3)\n",
    "results_df_no_sampling_3.to_pickle('dataframe_recap_no_sampling_3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26524\\1951077860.py:23: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df_no_sampling_4 = pd.concat([results_df_no_sampling_4, pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoostClassifier, Sampler: RandomOverSampler, Strategy: 0.05, F1 Score: 0.0109772831224272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoostClassifier, Sampler: RandomOverSampler, Strategy: 0.1, F1 Score: 0.0109772831224272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoostClassifier, Sampler: SMOTE, Strategy: 0.05, F1 Score: 0.0109772831224272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoostClassifier, Sampler: SMOTE, Strategy: 0.1, F1 Score: 0.0109772831224272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoostClassifier, Sampler: RandomUnderSampler, Strategy: 0.05, F1 Score: 0.0109772831224272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoostClassifier, Sampler: RandomUnderSampler, Strategy: 0.1, F1 Score: 0.0109772831224272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoostClassifier, Sampler: NearMiss, Strategy: 0.05, F1 Score: 0.0109772831224272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoostClassifier, Sampler: NearMiss, Strategy: 0.1, F1 Score: 0.0109772831224272\n",
      "                Model             Sampler  Sampling Strategy  F1 Score\n",
      "0  AdaBoostClassifier   RandomOverSampler               0.05  0.010977\n",
      "1  AdaBoostClassifier   RandomOverSampler               0.10  0.010977\n",
      "2  AdaBoostClassifier               SMOTE               0.05  0.010977\n",
      "3  AdaBoostClassifier               SMOTE               0.10  0.010977\n",
      "4  AdaBoostClassifier  RandomUnderSampler               0.05  0.010977\n",
      "5  AdaBoostClassifier  RandomUnderSampler               0.10  0.010977\n",
      "6  AdaBoostClassifier            NearMiss               0.05  0.010977\n",
      "7  AdaBoostClassifier            NearMiss               0.10  0.010977\n"
     ]
    }
   ],
   "source": [
    "# Définir les modèles à tester\n",
    "models = [AdaBoostClassifier()]\n",
    "\n",
    "# Initialiser un DataFrame pour stocker les résultats\n",
    "results_df_no_sampling_4 = pd.DataFrame(columns=['Model', 'Sampler', 'Sampling Strategy', 'F1 Score'])\n",
    "\n",
    "# Parcourir chaque modèle\n",
    "for model in models:\n",
    "    # Boucler sur chaque échantillonneur (sampler)\n",
    "    for sampler in samplers:\n",
    "        # Parcourir chaque valeur de sampling_strategy\n",
    "        for strategy in sampling_strategies:\n",
    "            # Entraîner le modèle sur les données d'entraînement d'origine\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Faire des prédictions sur l'ensemble de test\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Évaluer les performances du modèle\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            # Ajouter les résultats au DataFrame\n",
    "            results_df_no_sampling_4 = pd.concat([results_df_no_sampling_4, pd.DataFrame({\n",
    "                'Model': [model.__class__.__name__],\n",
    "                'Sampler': [sampler.__name__],\n",
    "                'Sampling Strategy': [strategy],\n",
    "                'F1 Score': [f1]\n",
    "            })], ignore_index=True)\n",
    "\n",
    "            # Afficher le message de progression\n",
    "            tqdm.write(f\"Model: {model.__class__.__name__}, Sampler: {sampler.__name__}, Strategy: {strategy}, F1 Score: {f1}\")\n",
    "\n",
    "# Afficher le tableau récapitulatif\n",
    "print(results_df_no_sampling_4)\n",
    "results_df_no_sampling_4.to_pickle('dataframe_recap_no_sampling_4.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25692\\2827257504.py:23: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df_no_sampling_5 = pd.concat([results_df_no_sampling_5, pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBClassifier, Sampler: RandomOverSampler, Strategy: 0.05, F1 Score: 0.06242712350883487\n",
      "Model: XGBClassifier, Sampler: RandomOverSampler, Strategy: 0.1, F1 Score: 0.06242712350883487\n",
      "Model: XGBClassifier, Sampler: SMOTE, Strategy: 0.05, F1 Score: 0.06242712350883487\n",
      "Model: XGBClassifier, Sampler: SMOTE, Strategy: 0.1, F1 Score: 0.06242712350883487\n",
      "Model: XGBClassifier, Sampler: RandomUnderSampler, Strategy: 0.05, F1 Score: 0.06242712350883487\n",
      "Model: XGBClassifier, Sampler: RandomUnderSampler, Strategy: 0.1, F1 Score: 0.06242712350883487\n",
      "Model: XGBClassifier, Sampler: NearMiss, Strategy: 0.05, F1 Score: 0.06242712350883487\n",
      "Model: XGBClassifier, Sampler: NearMiss, Strategy: 0.1, F1 Score: 0.06242712350883487\n",
      "           Model             Sampler  Sampling Strategy  F1 Score\n",
      "0  XGBClassifier   RandomOverSampler               0.05  0.062427\n",
      "1  XGBClassifier   RandomOverSampler               0.10  0.062427\n",
      "2  XGBClassifier               SMOTE               0.05  0.062427\n",
      "3  XGBClassifier               SMOTE               0.10  0.062427\n",
      "4  XGBClassifier  RandomUnderSampler               0.05  0.062427\n",
      "5  XGBClassifier  RandomUnderSampler               0.10  0.062427\n",
      "6  XGBClassifier            NearMiss               0.05  0.062427\n",
      "7  XGBClassifier            NearMiss               0.10  0.062427\n"
     ]
    }
   ],
   "source": [
    "# Définir les modèles à tester\n",
    "models = [XGBClassifier()]\n",
    "\n",
    "# Initialiser un DataFrame pour stocker les résultats\n",
    "results_df_no_sampling_5 = pd.DataFrame(columns=['Model', 'Sampler', 'Sampling Strategy', 'F1 Score'])\n",
    "\n",
    "# Parcourir chaque modèle\n",
    "for model in models:\n",
    "    # Boucler sur chaque échantillonneur (sampler)\n",
    "    for sampler in samplers:\n",
    "        # Parcourir chaque valeur de sampling_strategy\n",
    "        for strategy in sampling_strategies:\n",
    "            # Entraîner le modèle sur les données d'entraînement d'origine\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Faire des prédictions sur l'ensemble de test\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Évaluer les performances du modèle\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            # Ajouter les résultats au DataFrame\n",
    "            results_df_no_sampling_5 = pd.concat([results_df_no_sampling_5, pd.DataFrame({\n",
    "                'Model': [model.__class__.__name__],\n",
    "                'Sampler': [sampler.__name__],\n",
    "                'Sampling Strategy': [strategy],\n",
    "                'F1 Score': [f1]\n",
    "            })], ignore_index=True)\n",
    "\n",
    "            # Afficher le message de progression\n",
    "            tqdm.write(f\"Model: {model.__class__.__name__}, Sampler: {sampler.__name__}, Strategy: {strategy}, F1 Score: {f1}\")\n",
    "\n",
    "# Afficher le tableau récapitulatif\n",
    "print(results_df_no_sampling_5)\n",
    "results_df_no_sampling_5.to_pickle('dataframe_recap_no_sampling_5.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25692\\1301561485.py:23: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df_no_sampling_6 = pd.concat([results_df_no_sampling_6, pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression, Sampler: RandomOverSampler, Strategy: 0.05, F1 Score: 0.0075392038600723766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression, Sampler: RandomOverSampler, Strategy: 0.1, F1 Score: 0.0075392038600723766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression, Sampler: SMOTE, Strategy: 0.05, F1 Score: 0.0075392038600723766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression, Sampler: SMOTE, Strategy: 0.1, F1 Score: 0.0075392038600723766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression, Sampler: RandomUnderSampler, Strategy: 0.05, F1 Score: 0.0075392038600723766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression, Sampler: RandomUnderSampler, Strategy: 0.1, F1 Score: 0.0075392038600723766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression, Sampler: NearMiss, Strategy: 0.05, F1 Score: 0.0075392038600723766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression, Sampler: NearMiss, Strategy: 0.1, F1 Score: 0.0075392038600723766\n",
      "                Model             Sampler  Sampling Strategy  F1 Score\n",
      "0  LogisticRegression   RandomOverSampler               0.05  0.007539\n",
      "1  LogisticRegression   RandomOverSampler               0.10  0.007539\n",
      "2  LogisticRegression               SMOTE               0.05  0.007539\n",
      "3  LogisticRegression               SMOTE               0.10  0.007539\n",
      "4  LogisticRegression  RandomUnderSampler               0.05  0.007539\n",
      "5  LogisticRegression  RandomUnderSampler               0.10  0.007539\n",
      "6  LogisticRegression            NearMiss               0.05  0.007539\n",
      "7  LogisticRegression            NearMiss               0.10  0.007539\n"
     ]
    }
   ],
   "source": [
    "# Définir les modèles à tester\n",
    "models = [LogisticRegression()]\n",
    "\n",
    "# Initialiser un DataFrame pour stocker les résultats\n",
    "results_df_no_sampling_6 = pd.DataFrame(columns=['Model', 'Sampler', 'Sampling Strategy', 'F1 Score'])\n",
    "\n",
    "# Parcourir chaque modèle\n",
    "for model in models:\n",
    "    # Boucler sur chaque échantillonneur (sampler)\n",
    "    for sampler in samplers:\n",
    "        # Parcourir chaque valeur de sampling_strategy\n",
    "        for strategy in sampling_strategies:\n",
    "            # Entraîner le modèle sur les données d'entraînement d'origine\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Faire des prédictions sur l'ensemble de test\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Évaluer les performances du modèle\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            # Ajouter les résultats au DataFrame\n",
    "            results_df_no_sampling_6 = pd.concat([results_df_no_sampling_6, pd.DataFrame({\n",
    "                'Model': [model.__class__.__name__],\n",
    "                'Sampler': [sampler.__name__],\n",
    "                'Sampling Strategy': [strategy],\n",
    "                'F1 Score': [f1]\n",
    "            })], ignore_index=True)\n",
    "\n",
    "            # Afficher le message de progression\n",
    "            tqdm.write(f\"Model: {model.__class__.__name__}, Sampler: {sampler.__name__}, Strategy: {strategy}, F1 Score: {f1}\")\n",
    "\n",
    "# Afficher le tableau récapitulatif\n",
    "print(results_df_no_sampling_6)\n",
    "results_df_no_sampling_6.to_pickle('dataframe_recap_no_sampling_6.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
