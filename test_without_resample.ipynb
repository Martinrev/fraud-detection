{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dataframe.pkl', 'rb') as file:\n",
    "    df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On définit la partie Train et Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des dates limites pour les ensembles d'apprentissage et de test\n",
    "train_inf = '2017-02-01'\n",
    "train_sup = '2017-08-31'\n",
    "test_inf = '2017-09-01'\n",
    "test_sup = '2017-11-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.loc[(df['DateTransaction'] >= train_inf) & (df['DateTransaction'] <= train_sup)]\n",
    "X_train = train.drop(columns=['FlagImpaye','CodeDecision','DateTransaction'])\n",
    "y_train = train['FlagImpaye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.loc[(df['DateTransaction'] >= test_inf) & (df['DateTransaction'] <= test_sup)]\n",
    "X_test = test.drop(columns=['FlagImpaye','CodeDecision','DateTransaction'])\n",
    "y_test = test['FlagImpaye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3888468\n",
      "737068\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de chaque méthode d'échantillonage par modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, BorderlineSMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "#!pip install 'imblearn'\n",
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les stratégies d'échantillonnage\n",
    "sampling_strategies = [0.05, 0.1]  # Ajoutez les valeurs que vous souhaitez tester\n",
    "#on garde deux oversampling et deux undersampling\n",
    "samplers = [RandomOverSampler, SMOTE, RandomUnderSampler, NearMiss]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait tourner DecisionTreeClassifier, RandomForestClassifier, GradientBoostingClassifier,KNeighborsClassifier, SVC, adaboost, xgboost et LogisticRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les modèles à tester\n",
    "models = [DecisionTreeClassifier()]\n",
    "\n",
    "# Initialiser un DataFrame pour stocker les résultats\n",
    "results_df_no_sampling = pd.DataFrame(columns=['Model', 'Sampler', 'Sampling Strategy', 'F1 Score'])\n",
    "\n",
    "# Parcourir chaque modèle\n",
    "for model in models:\n",
    "    # Boucler sur chaque échantillonneur (sampler)\n",
    "    for sampler in samplers:\n",
    "        # Parcourir chaque valeur de sampling_strategy\n",
    "        for strategy in sampling_strategies:\n",
    "            # Entraîner le modèle sur les données d'entraînement d'origine\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Faire des prédictions sur l'ensemble de test\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Évaluer les performances du modèle\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            # Ajouter les résultats au DataFrame\n",
    "            results_df_no_sampling = pd.concat([results_df_no_sampling, pd.DataFrame({\n",
    "                'Model': [model.__class__.__name__],\n",
    "                'Sampler': [sampler.__name__],\n",
    "                'Sampling Strategy': [strategy],\n",
    "                'F1 Score': [f1]\n",
    "            })], ignore_index=True)\n",
    "\n",
    "            # Afficher le message de progression\n",
    "            tqdm.write(f\"Model: {model.__class__.__name__}, Sampler: {sampler.__name__}, Strategy: {strategy}, F1 Score: {f1}\")\n",
    "\n",
    "# Afficher le tableau récapitulatif\n",
    "print(results_df_no_sampling)\n",
    "results_df_no_sampling.to_pickle('dataframe_recap_no_sampling.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les modèles à tester\n",
    "models = [RandomForestClassifier()]\n",
    "\n",
    "# Initialiser un DataFrame pour stocker les résultats\n",
    "results_df_no_sampling_2 = pd.DataFrame(columns=['Model', 'Sampler', 'Sampling Strategy', 'F1 Score'])\n",
    "\n",
    "# Parcourir chaque modèle\n",
    "for model in models:\n",
    "    # Boucler sur chaque échantillonneur (sampler)\n",
    "    for sampler in samplers:\n",
    "        # Parcourir chaque valeur de sampling_strategy\n",
    "        for strategy in sampling_strategies:\n",
    "            # Entraîner le modèle sur les données d'entraînement d'origine\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Faire des prédictions sur l'ensemble de test\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Évaluer les performances du modèle\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            # Ajouter les résultats au DataFrame\n",
    "            results_df_no_sampling_2 = pd.concat([results_df_no_sampling_2, pd.DataFrame({\n",
    "                'Model': [model.__class__.__name__],\n",
    "                'Sampler': [sampler.__name__],\n",
    "                'Sampling Strategy': [strategy],\n",
    "                'F1 Score': [f1]\n",
    "            })], ignore_index=True)\n",
    "\n",
    "            # Afficher le message de progression\n",
    "            tqdm.write(f\"Model: {model.__class__.__name__}, Sampler: {sampler.__name__}, Strategy: {strategy}, F1 Score: {f1}\")\n",
    "\n",
    "# Afficher le tableau récapitulatif\n",
    "print(results_df_no_sampling_2)\n",
    "results_df_no_sampling_2.to_pickle('dataframe_recap_no_sampling_2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les modèles à tester\n",
    "models = [SVC()]\n",
    "\n",
    "# Initialiser un DataFrame pour stocker les résultats\n",
    "results_df_no_sampling_3 = pd.DataFrame(columns=['Model', 'Sampler', 'Sampling Strategy', 'F1 Score'])\n",
    "\n",
    "# Parcourir chaque modèle\n",
    "for model in models:\n",
    "    # Boucler sur chaque échantillonneur (sampler)\n",
    "    for sampler in samplers:\n",
    "        # Parcourir chaque valeur de sampling_strategy\n",
    "        for strategy in sampling_strategies:\n",
    "            # Entraîner le modèle sur les données d'entraînement d'origine\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Faire des prédictions sur l'ensemble de test\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Évaluer les performances du modèle\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            # Ajouter les résultats au DataFrame\n",
    "            results_df_no_sampling_3 = pd.concat([results_df_no_sampling_3, pd.DataFrame({\n",
    "                'Model': [model.__class__.__name__],\n",
    "                'Sampler': [sampler.__name__],\n",
    "                'Sampling Strategy': [strategy],\n",
    "                'F1 Score': [f1]\n",
    "            })], ignore_index=True)\n",
    "\n",
    "            # Afficher le message de progression\n",
    "            tqdm.write(f\"Model: {model.__class__.__name__}, Sampler: {sampler.__name__}, Strategy: {strategy}, F1 Score: {f1}\")\n",
    "\n",
    "# Afficher le tableau récapitulatif\n",
    "print(results_df_no_sampling_3)\n",
    "results_df_no_sampling_3.to_pickle('dataframe_recap_no_sampling_3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les modèles à tester\n",
    "models = [AdaBoostClassifier()]\n",
    "\n",
    "# Initialiser un DataFrame pour stocker les résultats\n",
    "results_df_no_sampling_4 = pd.DataFrame(columns=['Model', 'Sampler', 'Sampling Strategy', 'F1 Score'])\n",
    "\n",
    "# Parcourir chaque modèle\n",
    "for model in models:\n",
    "    # Boucler sur chaque échantillonneur (sampler)\n",
    "    for sampler in samplers:\n",
    "        # Parcourir chaque valeur de sampling_strategy\n",
    "        for strategy in sampling_strategies:\n",
    "            # Entraîner le modèle sur les données d'entraînement d'origine\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Faire des prédictions sur l'ensemble de test\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Évaluer les performances du modèle\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            # Ajouter les résultats au DataFrame\n",
    "            results_df_no_sampling_4 = pd.concat([results_df_no_sampling_4, pd.DataFrame({\n",
    "                'Model': [model.__class__.__name__],\n",
    "                'Sampler': [sampler.__name__],\n",
    "                'Sampling Strategy': [strategy],\n",
    "                'F1 Score': [f1]\n",
    "            })], ignore_index=True)\n",
    "\n",
    "            # Afficher le message de progression\n",
    "            tqdm.write(f\"Model: {model.__class__.__name__}, Sampler: {sampler.__name__}, Strategy: {strategy}, F1 Score: {f1}\")\n",
    "\n",
    "# Afficher le tableau récapitulatif\n",
    "print(results_df_no_sampling_4)\n",
    "results_df_no_sampling_4.to_pickle('dataframe_recap_no_sampling_4.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les modèles à tester\n",
    "models = [XGBClassifier()]\n",
    "\n",
    "# Initialiser un DataFrame pour stocker les résultats\n",
    "results_df_no_sampling_5 = pd.DataFrame(columns=['Model', 'Sampler', 'Sampling Strategy', 'F1 Score'])\n",
    "\n",
    "# Parcourir chaque modèle\n",
    "for model in models:\n",
    "    # Boucler sur chaque échantillonneur (sampler)\n",
    "    for sampler in samplers:\n",
    "        # Parcourir chaque valeur de sampling_strategy\n",
    "        for strategy in sampling_strategies:\n",
    "            # Entraîner le modèle sur les données d'entraînement d'origine\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Faire des prédictions sur l'ensemble de test\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Évaluer les performances du modèle\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            # Ajouter les résultats au DataFrame\n",
    "            results_df_no_sampling_5 = pd.concat([results_df_no_sampling_5, pd.DataFrame({\n",
    "                'Model': [model.__class__.__name__],\n",
    "                'Sampler': [sampler.__name__],\n",
    "                'Sampling Strategy': [strategy],\n",
    "                'F1 Score': [f1]\n",
    "            })], ignore_index=True)\n",
    "\n",
    "            # Afficher le message de progression\n",
    "            tqdm.write(f\"Model: {model.__class__.__name__}, Sampler: {sampler.__name__}, Strategy: {strategy}, F1 Score: {f1}\")\n",
    "\n",
    "# Afficher le tableau récapitulatif\n",
    "print(results_df_no_sampling_5)\n",
    "results_df_no_sampling_5.to_pickle('dataframe_recap_no_sampling_5.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les modèles à tester\n",
    "models = [LogisticRegression()]\n",
    "\n",
    "# Initialiser un DataFrame pour stocker les résultats\n",
    "results_df_no_sampling_6 = pd.DataFrame(columns=['Model', 'Sampler', 'Sampling Strategy', 'F1 Score'])\n",
    "\n",
    "# Parcourir chaque modèle\n",
    "for model in models:\n",
    "    # Boucler sur chaque échantillonneur (sampler)\n",
    "    for sampler in samplers:\n",
    "        # Parcourir chaque valeur de sampling_strategy\n",
    "        for strategy in sampling_strategies:\n",
    "            # Entraîner le modèle sur les données d'entraînement d'origine\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Faire des prédictions sur l'ensemble de test\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Évaluer les performances du modèle\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            # Ajouter les résultats au DataFrame\n",
    "            results_df_no_sampling_6 = pd.concat([results_df_no_sampling_6, pd.DataFrame({\n",
    "                'Model': [model.__class__.__name__],\n",
    "                'Sampler': [sampler.__name__],\n",
    "                'Sampling Strategy': [strategy],\n",
    "                'F1 Score': [f1]\n",
    "            })], ignore_index=True)\n",
    "\n",
    "            # Afficher le message de progression\n",
    "            tqdm.write(f\"Model: {model.__class__.__name__}, Sampler: {sampler.__name__}, Strategy: {strategy}, F1 Score: {f1}\")\n",
    "\n",
    "# Afficher le tableau récapitulatif\n",
    "print(results_df_no_sampling_6)\n",
    "results_df_no_sampling_6.to_pickle('dataframe_recap_no_sampling_6.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
